{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omkar\\anaconda3\\envs\\RL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from agent import DuelingDDQNAgent\n",
    "from util import make_env, plot_learning_curve\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Reinforcement Learning\\My codes\\Dueling DDQN\\agent.py:96: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:30.)\n",
      "  q_next[dones] = 0.0\n",
      "C:\\Users\\Omkar\\anaconda3\\envs\\RL\\lib\\site-packages\\torch\\autograd\\__init__.py:147: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:30.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score:  0.0 avg_score: 0.0 best_score -inf epsilon 1.00 steps  100\n",
      "episode  1 score:  -2.0 avg_score: -1.0 best_score 0.0 epsilon 1.00 steps  200\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env_name ='PongNoFrameskip-v4'\n",
    "    env = make_env(env_name)\n",
    "    best_score = -np.inf\n",
    "    load_checkpoint = False\n",
    "    if(not os.path.exists('models')):\n",
    "        os.mkdir('models/')\n",
    "    if(not os.path.exists('plots')):\n",
    "        os.mkdir('plots/')\n",
    "    \n",
    "    n_games = 3\n",
    "    agent = DuelingDDQNAgent(gamma = 0.99, epsilon= 1.0, lr = 0.00001, input_dims=(env.observation_space.shape),\n",
    "                        n_actions= env.action_space.n, mem_size= 5000, eps_min = 0.1,\n",
    "                        batch_size = 32, replace = 1000, eps_dec = 1e-5, chkpt_dir='models/', algo = 'Dueling_DDQNAgent',\n",
    "                        env_name = env_name)\n",
    "\n",
    "    if load_checkpoint:\n",
    "        agent.load_models()\n",
    "\n",
    "    fname = agent.algo + '_' + agent.env_name +'_lr'+ str(agent.lr) + '_' + str(n_games)+'games'\n",
    "\n",
    "    figure_file = 'plots/' + fname + '.png'\n",
    "\n",
    "    n_steps = 0\n",
    "    scores, eps_history, steps_array = [], [], []\n",
    "\n",
    "    for i in range(n_games):\n",
    "        done = False\n",
    "        score = 0\n",
    "        observation = env.reset()\n",
    "\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "\n",
    "            if not load_checkpoint:\n",
    "                agent.store_transition(observation, action, reward, observation_, int(done))\n",
    "\n",
    "                agent.learn()\n",
    "            observation = observation_\n",
    "            n_steps += 1\n",
    "            if(n_steps%100 == 0):\n",
    "                break\n",
    "\n",
    "        steps_array.append(n_steps)\n",
    "        scores.append(score)\n",
    "        avg_score = np.mean(scores[-100:])\n",
    "\n",
    "        print('episode ', i, 'score: ', score, 'avg_score: %.1f best_score %.1f epsilon %.2f' %\n",
    "        (avg_score, best_score, agent.epsilon), 'steps ', n_steps)\n",
    "\n",
    "        # if avg_score > best_score:\n",
    "        #     if not load_checkpoint:\n",
    "        #         agent.save_models()\n",
    "\n",
    "        best_score = avg_score\n",
    "\n",
    "        if score > best_score:\n",
    "          if not load_checkpoint:\n",
    "                agent.save_models()\n",
    "          best_score = score \n",
    "\n",
    "        eps_history.append(agent.epsilon)\n",
    "\n",
    "    plot_learning_curve(steps_array, scores, eps_history, figure_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76fc2bd47c0ab4cfe21d0e9fdf77c16ad014876084344484d53440e39eda7dad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('Atari-gym': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
